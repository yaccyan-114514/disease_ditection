"""
ä»æ–‡ä»¶å¤¹åŠ è½½æ•°æ®é›†çš„è®­ç»ƒè„šæœ¬
é€‚ç”¨äºæ‰‹åŠ¨ä¸‹è½½å¹¶è§£å‹çš„æ•°æ®é›†
"""
import os
import json
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import MobileNetV3Small
from tensorflow.keras import layers as L
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report
from collections import Counter

# é…ç½®
IMG_SIZE = 160  # ä¸APIæœåŠ¡ä¿æŒä¸€è‡´
BATCH_SIZE = 32
EPOCHS = 50
SEED = 42

# è®¾ç½®éšæœºç§å­
tf.random.set_seed(SEED)
np.random.seed(SEED)

# æ•°æ®è·¯å¾„
DATA_DIR = os.path.expanduser('~/tensorflow_datasets/plant_village/1.0.2/Plant_leave_diseases_dataset_without_augmentation')
OUTPUT_DIR = "streamlit_app/model"
os.makedirs(OUTPUT_DIR, exist_ok=True)

print("=" * 60)
print("ğŸŒ± æ¤ç‰©ç—…å®³è¯†åˆ«æ¨¡å‹è®­ç»ƒï¼ˆä»æ–‡ä»¶å¤¹åŠ è½½ï¼‰")
print("=" * 60)

# ==================== æ­¥éª¤1: æ£€æŸ¥æ•°æ®ç›®å½• ====================
print("\n[1/5] æ£€æŸ¥æ•°æ®ç›®å½•...")

if not os.path.exists(DATA_DIR):
    print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {DATA_DIR}")
    print(f"è¯·ç¡®ä¿æ•°æ®é›†å·²è§£å‹åˆ°è¯¥ç›®å½•")
    exit(1)

# è·å–æ‰€æœ‰ç±»åˆ«
class_dirs = [d for d in os.listdir(DATA_DIR) 
              if os.path.isdir(os.path.join(DATA_DIR, d)) 
              and not d.startswith('.')]

# è¿‡æ»¤æ‰ Background_without_leavesï¼ˆæ ¹æ®TFDSè¯´æ˜ï¼Œè¿™ä¸ªç±»åˆ«ä¸åœ¨åŸå§‹æ•°æ®é›†ä¸­ï¼‰
class_dirs = [d for d in class_dirs if d != 'Background_without_leaves']

class_dirs.sort()
NUM_CLASSES = len(class_dirs)

# ä¿å­˜æœ‰æ•ˆçš„ç±»åˆ«åˆ—è¡¨ï¼Œç”¨äºImageDataGenerator
valid_classes = sorted(class_dirs)

print(f"âœ“ æ•°æ®ç›®å½•å­˜åœ¨: {DATA_DIR}")
print(f"âœ“ æ‰¾åˆ° {NUM_CLASSES} ä¸ªç±»åˆ«")

# ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°
class_counts = {}
for class_dir in class_dirs:
    class_path = os.path.join(DATA_DIR, class_dir)
    count = len([f for f in os.listdir(class_path) 
                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    class_counts[class_dir] = count
    print(f"  - {class_dir}: {count} å¼ å›¾ç‰‡")

total_images = sum(class_counts.values())
print(f"\næ€»å›¾ç‰‡æ•°: {total_images}")

# ==================== æ­¥éª¤2: å‡†å¤‡æ•°æ®ç”Ÿæˆå™¨ ====================
print("\n[2/5] å‡†å¤‡æ•°æ®ç”Ÿæˆå™¨...")

# æ•°æ®é¢„å¤„ç†å‡½æ•°
def preprocess_input(x):
    """MobileNetV3é¢„å¤„ç†"""
    from tensorflow.keras.applications.mobilenet_v3 import preprocess_input as mobilenet_preprocess
    return mobilenet_preprocess(x)

# è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨ï¼ˆä¸ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œå› ä¸ºæœ€ä½³é…ç½®æ˜¯Falseï¼‰
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    validation_split=0.15,  # 15%ä½œä¸ºéªŒè¯é›†
    rescale=1.0  # é¢„å¤„ç†å‡½æ•°å·²ç»å¤„ç†äº†å½’ä¸€åŒ–
)

# éªŒè¯æ•°æ®ç”Ÿæˆå™¨ï¼ˆä¸ä½¿ç”¨æ•°æ®å¢å¼ºï¼‰
val_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    validation_split=0.15,
    rescale=1.0
)

# æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨ï¼ˆä»è®­ç»ƒé›†ä¸­å†åˆ†15%ä½œä¸ºæµ‹è¯•é›†ï¼‰
# æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨validation_split=0.15ï¼Œç„¶åä»å‰©ä½™çš„85%ä¸­å†åˆ†15%ä½œä¸ºæµ‹è¯•é›†
# å®é™…åˆ’åˆ†ï¼š70%è®­ç»ƒï¼Œ15%éªŒè¯ï¼Œ15%æµ‹è¯•

# åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨ï¼ˆæŒ‡å®šclasseså‚æ•°ï¼Œæ’é™¤Background_without_leavesï¼‰
train_gen = train_datagen.flow_from_directory(
    DATA_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    subset='training',
    class_mode='sparse',
    classes=valid_classes,  # åªä½¿ç”¨æœ‰æ•ˆçš„ç±»åˆ«ï¼Œæ’é™¤Background_without_leaves
    seed=SEED,
    shuffle=True
)

val_gen = val_datagen.flow_from_directory(
    DATA_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    subset='validation',
    class_mode='sparse',
    classes=valid_classes,  # åªä½¿ç”¨æœ‰æ•ˆçš„ç±»åˆ«
    seed=SEED,
    shuffle=False
)

# è·å–ç±»åˆ«åç§°ï¼ˆæŒ‰é¡ºåºï¼Œä¸ImageDataGeneratorçš„class_indicesé¡ºåºä¸€è‡´ï¼‰
class_names = sorted(valid_classes)

# éªŒè¯ç±»åˆ«æ•°é‡å’Œç´¢å¼•èŒƒå›´
if len(train_gen.class_indices) != NUM_CLASSES:
    print(f"âŒ é”™è¯¯: ç±»åˆ«æ•°é‡ä¸åŒ¹é…")
    print(f"  è®­ç»ƒç”Ÿæˆå™¨: {len(train_gen.class_indices)} ä¸ªç±»åˆ«")
    print(f"  é¢„æœŸ: {NUM_CLASSES} ä¸ªç±»åˆ«")
    print(f"  ç±»åˆ«ç´¢å¼•æ˜ å°„: {train_gen.class_indices}")
    exit(1)

# éªŒè¯ç±»åˆ«ç´¢å¼•èŒƒå›´ï¼ˆåº”è¯¥æ˜¯0åˆ°NUM_CLASSES-1ï¼‰
max_index = max(train_gen.class_indices.values())
min_index = min(train_gen.class_indices.values())
if max_index >= NUM_CLASSES or min_index < 0:
    print(f"âŒ é”™è¯¯: ç±»åˆ«ç´¢å¼•è¶…å‡ºèŒƒå›´")
    print(f"  ç´¢å¼•èŒƒå›´: [{min_index}, {max_index}]")
    print(f"  æœ‰æ•ˆèŒƒå›´: [0, {NUM_CLASSES})")
    print(f"  ç±»åˆ«ç´¢å¼•æ˜ å°„: {train_gen.class_indices}")
    exit(1)

print(f"âœ“ ç±»åˆ«ç´¢å¼•éªŒè¯é€šè¿‡: [{min_index}, {max_index}]")

print(f"âœ“ æ•°æ®ç”Ÿæˆå™¨å‡†å¤‡å®Œæˆ")
print(f"  - è®­ç»ƒé›†: {train_gen.samples} å¼ å›¾ç‰‡")
print(f"  - éªŒè¯é›†: {val_gen.samples} å¼ å›¾ç‰‡")
print(f"  - ç±»åˆ«æ•°: {NUM_CLASSES}")

# ==================== æ­¥éª¤3: è®¡ç®—ç±»åˆ«æƒé‡ ====================
print("\n[3/5] è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆè§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼‰...")

# æ”¶é›†è®­ç»ƒæ ‡ç­¾
train_labels = []
for i in range(len(train_gen)):
    _, labels = train_gen[i]
    train_labels.extend(labels)
    if i >= len(train_gen) - 1:  # åªæ”¶é›†ä¸€æ¬¡å®Œæ•´çš„æ•°æ®
        break

# é‡ç½®ç”Ÿæˆå™¨
train_gen.reset()

# è®¡ç®—ç±»åˆ«æƒé‡
unique_labels = np.unique(train_labels)
class_weights = compute_class_weight(
    'balanced',
    classes=unique_labels,
    y=train_labels
)
class_weight_dict = dict(zip(unique_labels, class_weights))

print(f"âœ“ ç±»åˆ«æƒé‡è®¡ç®—å®Œæˆ")
print(f"  - æœ€å°æƒé‡: {min(class_weights):.3f}")
print(f"  - æœ€å¤§æƒé‡: {max(class_weights):.3f}")

# æ˜¾ç¤ºTomatoç±»åˆ«æƒé‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
tomato_classes = [i for i, name in enumerate(class_names) if name.startswith("Tomato")]
if tomato_classes:
    tomato_weight = class_weights[tomato_classes[0]]
    print(f"  - Tomatoç±»åˆ«æƒé‡: {tomato_weight:.3f}")

# ==================== æ­¥éª¤4: æ„å»ºæ¨¡å‹ ====================
print("\n[4/5] æ„å»ºæ¨¡å‹...")

def build_model(num_classes, img_size=(IMG_SIZE, IMG_SIZE)):
    """æ„å»ºMobileNetV3Smallæ¨¡å‹"""
    # åŸºç¡€æ¨¡å‹ï¼ˆä½¿ç”¨ImageNeté¢„è®­ç»ƒæƒé‡ï¼‰
    base = MobileNetV3Small(
        input_shape=(img_size[0], img_size[1], 3),
        include_top=False,
        weights='imagenet'
    )
    base.trainable = False  # å†»ç»“åŸºç¡€æ¨¡å‹
    
    # åˆ†ç±»å¤´
    inp = L.Input(shape=(img_size[0], img_size[1], 3), name="input")
    x = base(inp)
    x = L.GlobalAveragePooling2D(name="gap")(x)
    x = L.Dropout(0.1, name="dropout")(x)
    
    x = L.Dense(256, use_bias=False, name="dense256")(x)
    x = L.BatchNormalization(name="bn")(x)
    x = L.Activation('swish', name="swish")(x)
    
    out = L.Dense(num_classes, activation='softmax', dtype='float32', name="pred")(x)
    
    model = tf.keras.Model(inp, out, name="plant_disease_classifier")
    return model

model = build_model(NUM_CLASSES, (IMG_SIZE, IMG_SIZE))

# ç¼–è¯‘æ¨¡å‹
model.compile(
    optimizer=tf.keras.optimizers.AdamW(
        learning_rate=0.001,
        weight_decay=1.9e-5
    ),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print(f"âœ“ æ¨¡å‹æ„å»ºå®Œæˆ")
print(f"  - æ€»å‚æ•°: {model.count_params():,}")
print(f"  - å¯è®­ç»ƒå‚æ•°: {sum([tf.size(w).numpy() for w in model.trainable_weights]):,}")

# ==================== æ­¥éª¤5: è®­ç»ƒæ¨¡å‹ ====================
print("\n[5/5] å¼€å§‹è®­ç»ƒæ¨¡å‹...")
print("=" * 60)

# å›è°ƒå‡½æ•°
callbacks = [
    EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True,
        verbose=1
    ),
    ModelCheckpoint(
        filepath=os.path.join(OUTPUT_DIR, 'best_model_tuned.weights.h5'),
        monitor='val_accuracy',
        save_best_only=True,
        save_weights_only=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    )
]

# è®¡ç®—æ­¥æ•°
steps_per_epoch = train_gen.samples // BATCH_SIZE
validation_steps = val_gen.samples // BATCH_SIZE

print(f"è®­ç»ƒé…ç½®:")
print(f"  - è®­ç»ƒè½®æ•°: {EPOCHS}")
print(f"  - æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
print(f"  - å›¾ç‰‡å°ºå¯¸: {IMG_SIZE}x{IMG_SIZE}")
print(f"  - æ¯è½®æ­¥æ•°: {steps_per_epoch}")
print(f"  - éªŒè¯æ­¥æ•°: {validation_steps}")
print(f"  - ä½¿ç”¨ç±»åˆ«æƒé‡: æ˜¯")
print("=" * 60)

# å¼€å§‹è®­ç»ƒ
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=EPOCHS,
    steps_per_epoch=steps_per_epoch,
    validation_steps=validation_steps,
    callbacks=callbacks,
    class_weight=class_weight_dict,  # ä½¿ç”¨ç±»åˆ«æƒé‡
    verbose=1
)

print("\n" + "=" * 60)
print("âœ“ è®­ç»ƒå®Œæˆï¼")
print("=" * 60)

# ==================== è¯„ä¼°æ¨¡å‹ ====================
print("\nè¯„ä¼°æ¨¡å‹...")

# åˆ›å»ºæµ‹è¯•æ•°æ®ç”Ÿæˆå™¨ï¼ˆä»è®­ç»ƒé›†ä¸­å†åˆ†ä¸€éƒ¨åˆ†ä½œä¸ºæµ‹è¯•é›†ï¼‰
# è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨éªŒè¯é›†ä½œä¸ºæµ‹è¯•é›†ï¼ˆå› ä¸ºImageDataGeneratorçš„validation_splité™åˆ¶ï¼‰
test_gen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    validation_split=0.15
).flow_from_directory(
    DATA_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    subset='validation',
    class_mode='sparse',
    classes=valid_classes,  # åªä½¿ç”¨æœ‰æ•ˆçš„ç±»åˆ«
    seed=SEED,
    shuffle=False
)

test_loss, test_acc = model.evaluate(test_gen, verbose=1)
print(f"\nğŸ“Š æµ‹è¯•é›†ç»“æœ:")
print(f"  - æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2%}")
print(f"  - æµ‹è¯•æŸå¤±: {test_loss:.4f}")

# ==================== ä¿å­˜æ¨¡å‹å’Œç±»åˆ«åç§° ====================
print("\nä¿å­˜æ¨¡å‹æ–‡ä»¶...")

# ä¿å­˜æƒé‡ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ä¿å­˜ï¼‰
weights_path = os.path.join(OUTPUT_DIR, 'best_model_tuned.weights.h5')
if not os.path.exists(weights_path):
    model.save_weights(weights_path)
    print(f"âœ“ æ¨¡å‹æƒé‡å·²ä¿å­˜: {weights_path}")

# ä¿å­˜ç±»åˆ«åç§°ï¼ˆé‡è¦ï¼ï¼‰
class_names_path = os.path.join(OUTPUT_DIR, 'class_names.json')
with open(class_names_path, 'w', encoding='utf-8') as f:
    json.dump(class_names, f, ensure_ascii=False, indent=2)
print(f"âœ“ ç±»åˆ«åç§°å·²ä¿å­˜: {class_names_path}")

print("\n" + "=" * 60)
print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
print("=" * 60)
print(f"\næ¨¡å‹æ–‡ä»¶å·²ä¿å­˜åˆ°: {OUTPUT_DIR}/")
print(f"  - best_model_tuned.weights.h5 (æ¨¡å‹æƒé‡)")
print(f"  - class_names.json (ç±»åˆ«åç§°)")
print(f"\nç°åœ¨å¯ä»¥:")
print(f"  1. é‡å¯APIæœåŠ¡: python api_service.py")
print(f"  2. æµ‹è¯•è¯†åˆ«åŠŸèƒ½")
print(f"  3. è¿è¡Œè¯Šæ–­è„šæœ¬: python debug_model.py <æµ‹è¯•å›¾ç‰‡>")
print("=" * 60)
